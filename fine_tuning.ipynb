{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5f8541-817b-4247-a115-597c97c8f0ee",
   "metadata": {},
   "source": [
    "resources:\n",
    "- https://huggingface.co/docs/transformers/training\n",
    "- Universal Language Model Fine-Tuning for Text Classification: https://arxiv.org/abs/1801.06146\n",
    "- https://learn.deeplearning.ai/finetuning-large-language-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795eb87e-4777-49c6-8cdb-dc757c0e9395",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f2bfd3ec-8a81-4f8c-8ef5-bb3d30d87884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config # need to also pip install python-configuration if created in a new env\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "\n",
    "from utilities import *\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a6f80-4f09-4f8b-9e84-0afaac92afe0",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "311bf92b-68b8-4926-80be-a1d3e4aaaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on https://huggingface.co/datasets/medmcqa?row=0 dataset\n",
    "dataset_path = \"medmcqa\"\n",
    "use_hf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cee03d14-4db9-4ac0-a4bd-080fafc56f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if use_hf:\n",
    "    dataset = datasets.load_dataset(dataset_path)\n",
    "else:\n",
    "    dataset = load_dataset(dataset_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e85df6ed-0d48-438f-a430-a8776704a4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>opa</th>\n",
       "      <th>opb</th>\n",
       "      <th>opc</th>\n",
       "      <th>opd</th>\n",
       "      <th>cop</th>\n",
       "      <th>choice_type</th>\n",
       "      <th>exp</th>\n",
       "      <th>subject_name</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45258d3d-b974-44dd-a161-c3fccbdadd88</td>\n",
       "      <td>Which of the following is not true for myelina...</td>\n",
       "      <td>Impulse through myelinated fibers is slower th...</td>\n",
       "      <td>Membrane currents are generated at nodes of Ra...</td>\n",
       "      <td>Saltatory conduction of impulses is seen</td>\n",
       "      <td>Local anesthesia is effective only when the ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>multi</td>\n",
       "      <td>None</td>\n",
       "      <td>Physiology</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b944ada9-d776-4c2a-9180-3ae5f393f72d</td>\n",
       "      <td>Which of the following is not true about glome...</td>\n",
       "      <td>The oncotic pressure of the fluid leaving the ...</td>\n",
       "      <td>Glucose concentration in the capillaries is th...</td>\n",
       "      <td>Constriction of afferent aeriole decreases the...</td>\n",
       "      <td>Hematocrit of the fluid leaving the capillarie...</td>\n",
       "      <td>0</td>\n",
       "      <td>multi</td>\n",
       "      <td>Ans-a. The oncotic pressure of the fluid leavi...</td>\n",
       "      <td>Physiology</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b64a9cd7-d076-4c55-8be1-f9c44fece6cc</td>\n",
       "      <td>A 29 yrs old woman with a pregnancy of 17 week...</td>\n",
       "      <td>No test is required now as her age is below 35...</td>\n",
       "      <td>Ultra sound at this point of time will definit...</td>\n",
       "      <td>Amniotic fluid samples plus chromosomal analys...</td>\n",
       "      <td>blood screening at this point of time will cle...</td>\n",
       "      <td>2</td>\n",
       "      <td>single</td>\n",
       "      <td>None</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c6365cce-507c-40f6-90a2-46b867f47b6e</td>\n",
       "      <td>Axonal transport is:</td>\n",
       "      <td>Antegrade</td>\n",
       "      <td>Retrograde</td>\n",
       "      <td>Antegrade and retrograde</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>multi</td>\n",
       "      <td>Fast anterograde (400 mm/day) transport occurs...</td>\n",
       "      <td>Physiology</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72c1c5e0-b64f-4eef-bf22-ecfb60c5c19c</td>\n",
       "      <td>Low insulin to glucagon ratio is seen in all o...</td>\n",
       "      <td>Glycogen synthesis</td>\n",
       "      <td>Glycogen breakdown</td>\n",
       "      <td>Gluconeogenesis</td>\n",
       "      <td>Ketogenesis</td>\n",
       "      <td>0</td>\n",
       "      <td>multi</td>\n",
       "      <td>Answer- A. Glycogen synthesisLow insulin to gl...</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17360c6c-2c98-4fe2-aa85-487dcf4678df</td>\n",
       "      <td>Concentration of tropicamide:</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>Answer- A. 0.01Tropicamide is the shoest actin...</td>\n",
       "      <td>Ophthalmology</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62fa6f78-1964-4249-974b-6fcbbd7fc9ba</td>\n",
       "      <td>Which of the following statements is true rega...</td>\n",
       "      <td>Pregnant woman with sore throat can be staed i...</td>\n",
       "      <td>People on long-term steroids cannot receive Os...</td>\n",
       "      <td>Category B concerns with low risk cases</td>\n",
       "      <td>Category B patients have to undergo immediate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>multi</td>\n",
       "      <td>Ans: A. Pregnant woman with sore throat can be...</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ce49098b-cc48-4168-859e-936e3e0c7459</td>\n",
       "      <td>Which of the following are not a branch of ext...</td>\n",
       "      <td>Sphenopalatine aery</td>\n",
       "      <td>Anterior ethmoidal aery</td>\n",
       "      <td>Greater palatine aery</td>\n",
       "      <td>Septal branch of superior labial aery</td>\n",
       "      <td>1</td>\n",
       "      <td>single</td>\n",
       "      <td>*Kiesselbach's plexus: Antero superior pa is s...</td>\n",
       "      <td>Anatomy</td>\n",
       "      <td>AIIMS 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18d5c4a1-cb81-41a8-9bfc-b6f7dec431d2</td>\n",
       "      <td>Diagnosis of the following ECG-</td>\n",
       "      <td>Ventricular bigeminy</td>\n",
       "      <td>Electrical alternans</td>\n",
       "      <td>P pulmonale</td>\n",
       "      <td>Left ventricular failure</td>\n",
       "      <td>1</td>\n",
       "      <td>single</td>\n",
       "      <td>Option A- Broad QRS complex with normal sinus ...</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>AIIMS 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>de09d388-bd4e-42a9-ac6b-ee2d95f822e2</td>\n",
       "      <td>A blue new born presents with cyanosis. The Xâ€“...</td>\n",
       "      <td>Ebstein's anomaly</td>\n",
       "      <td>Pulmonary atresia</td>\n",
       "      <td>Transposition of great arteries</td>\n",
       "      <td>Tetralogy of fallot</td>\n",
       "      <td>1</td>\n",
       "      <td>multi</td>\n",
       "      <td>The findings in this newborn are\\nCyanosis at ...</td>\n",
       "      <td>Pediatrics</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  45258d3d-b974-44dd-a161-c3fccbdadd88   \n",
       "1  b944ada9-d776-4c2a-9180-3ae5f393f72d   \n",
       "2  b64a9cd7-d076-4c55-8be1-f9c44fece6cc   \n",
       "3  c6365cce-507c-40f6-90a2-46b867f47b6e   \n",
       "4  72c1c5e0-b64f-4eef-bf22-ecfb60c5c19c   \n",
       "5  17360c6c-2c98-4fe2-aa85-487dcf4678df   \n",
       "6  62fa6f78-1964-4249-974b-6fcbbd7fc9ba   \n",
       "7  ce49098b-cc48-4168-859e-936e3e0c7459   \n",
       "8  18d5c4a1-cb81-41a8-9bfc-b6f7dec431d2   \n",
       "9  de09d388-bd4e-42a9-ac6b-ee2d95f822e2   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which of the following is not true for myelina...   \n",
       "1  Which of the following is not true about glome...   \n",
       "2  A 29 yrs old woman with a pregnancy of 17 week...   \n",
       "3                               Axonal transport is:   \n",
       "4  Low insulin to glucagon ratio is seen in all o...   \n",
       "5                      Concentration of tropicamide:   \n",
       "6  Which of the following statements is true rega...   \n",
       "7  Which of the following are not a branch of ext...   \n",
       "8                    Diagnosis of the following ECG-   \n",
       "9  A blue new born presents with cyanosis. The Xâ€“...   \n",
       "\n",
       "                                                 opa  \\\n",
       "0  Impulse through myelinated fibers is slower th...   \n",
       "1  The oncotic pressure of the fluid leaving the ...   \n",
       "2  No test is required now as her age is below 35...   \n",
       "3                                          Antegrade   \n",
       "4                                 Glycogen synthesis   \n",
       "5                                               0.01   \n",
       "6  Pregnant woman with sore throat can be staed i...   \n",
       "7                                Sphenopalatine aery   \n",
       "8                               Ventricular bigeminy   \n",
       "9                                  Ebstein's anomaly   \n",
       "\n",
       "                                                 opb  \\\n",
       "0  Membrane currents are generated at nodes of Ra...   \n",
       "1  Glucose concentration in the capillaries is th...   \n",
       "2  Ultra sound at this point of time will definit...   \n",
       "3                                         Retrograde   \n",
       "4                                 Glycogen breakdown   \n",
       "5                                               0.02   \n",
       "6  People on long-term steroids cannot receive Os...   \n",
       "7                            Anterior ethmoidal aery   \n",
       "8                               Electrical alternans   \n",
       "9                                  Pulmonary atresia   \n",
       "\n",
       "                                                 opc  \\\n",
       "0           Saltatory conduction of impulses is seen   \n",
       "1  Constriction of afferent aeriole decreases the...   \n",
       "2  Amniotic fluid samples plus chromosomal analys...   \n",
       "3                           Antegrade and retrograde   \n",
       "4                                    Gluconeogenesis   \n",
       "5                                               0.03   \n",
       "6            Category B concerns with low risk cases   \n",
       "7                              Greater palatine aery   \n",
       "8                                        P pulmonale   \n",
       "9                    Transposition of great arteries   \n",
       "\n",
       "                                                 opd  cop choice_type  \\\n",
       "0  Local anesthesia is effective only when the ne...    0       multi   \n",
       "1  Hematocrit of the fluid leaving the capillarie...    0       multi   \n",
       "2  blood screening at this point of time will cle...    2      single   \n",
       "3                                               None    2       multi   \n",
       "4                                        Ketogenesis    0       multi   \n",
       "5                                               0.04    0      single   \n",
       "6  Category B patients have to undergo immediate ...    0       multi   \n",
       "7              Septal branch of superior labial aery    1      single   \n",
       "8                           Left ventricular failure    1      single   \n",
       "9                                Tetralogy of fallot    1       multi   \n",
       "\n",
       "                                                 exp   subject_name  \\\n",
       "0                                               None     Physiology   \n",
       "1  Ans-a. The oncotic pressure of the fluid leavi...     Physiology   \n",
       "2                                               None       Medicine   \n",
       "3  Fast anterograde (400 mm/day) transport occurs...     Physiology   \n",
       "4  Answer- A. Glycogen synthesisLow insulin to gl...   Biochemistry   \n",
       "5  Answer- A. 0.01Tropicamide is the shoest actin...  Ophthalmology   \n",
       "6  Ans: A. Pregnant woman with sore throat can be...       Medicine   \n",
       "7  *Kiesselbach's plexus: Antero superior pa is s...        Anatomy   \n",
       "8  Option A- Broad QRS complex with normal sinus ...       Medicine   \n",
       "9  The findings in this newborn are\\nCyanosis at ...     Pediatrics   \n",
       "\n",
       "   topic_name  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "5        None  \n",
       "6        None  \n",
       "7  AIIMS 2017  \n",
       "8  AIIMS 2017  \n",
       "9        None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual inference on dataset\n",
    "# might be worth only evaluating answers with explanations\n",
    "print(val_dataset.to_pandas()['cop'].unique())\n",
    "val_dataset.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a9876-75a3-42d6-9b2e-af5d2b1aac67",
   "metadata": {},
   "source": [
    "### Instruction Fine Tuning - Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b1dd62-ad11-4494-a27c-ce260d311865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction and input templates\n",
    "# for other tasks, can format instruction template. contant for this dataset\n",
    "instruction_template = \"Answer the following multiple-choice question.\"\n",
    "input_template = \"\"\"\n",
    "### Question: {question} \n",
    "### Answers: \n",
    "# {a}\n",
    "# {b} \n",
    "# {c} \n",
    "# {d}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eeebf44-04db-4de1-ac42-7945243e79be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt templates\n",
    "\n",
    "prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with inputs that provide further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_template_without_instruction = \"\"\"\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76cc0cea-7b91-4d8f-8086-565638161ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydrating dataset with instruction prompts\n",
    "# row based\n",
    "\n",
    "def hydrate(row):\n",
    "    input = input_template.format(\n",
    "        question = row['question'],\n",
    "        a = row['opa'][0],\n",
    "        b = row['opb'][0],\n",
    "        c = row['opc'][0],\n",
    "        d = row['opd'][0]\n",
    "    )\n",
    "    # prompt hydration\n",
    "    processed_prompt = prompt_template_without_instruction.format(input=input)\n",
    "    \n",
    "    if row['cop'][0] == -1 or not row['exp'][0]: # test dataset\n",
    "        output = \"N/A\"\n",
    "    else: # training and val datasets\n",
    "        # processed_prompt = prompt_template_with_input.format(instruction=instruction_template, input=input)\n",
    "        output = str(row['cop'][0]) + ': ' + row['exp'][0]\n",
    "    \n",
    "    return {\"input\": processed_prompt, \"output\": output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358c11f-2f65-4b38-a0de-9fad6a3ccc18",
   "metadata": {},
   "source": [
    "### Instruction Fine Tuning - Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efb540b6-f11a-46dc-83d9-77f88cff65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base llama model\n",
    "model_name = \"EleutherAI/pythia-410m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d6c62a2-3acb-4cdb-af46-b7e29f6ca82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b484176-b5c6-4455-ad0e-0252066e8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(row):\n",
    "    qa_dict = hydrate(row)\n",
    "    text = qa_dict['input'] + qa_dict[\"output\"]\n",
    "\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bac79f3e-614e-4196-a7d1-9d9f6b00bdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff6ca54c90c481e86c327ae92eb09e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604b546da37b457db47d65415677db7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6fe59a6f584e009cd5c7b26ba81d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 182822\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 6150\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4183\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c699fcfa-90d6-4cf8-91c2-5c6e4d4c37d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 182822\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6150\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4183\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add labels for trainer param\n",
    "for split in tokenized_dataset.keys():\n",
    "    tokenized_dataset[split] = tokenized_dataset[split].add_column(\"labels\", tokenized_dataset[split][\"input_ids\"])\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf6213b0-49c1-4a99-a0cd-9664a66ed735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02e8ad9d7b441f397e15becee748cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c57a85278944b7943d3b52a0ccd015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085dfd3eafc842a8a9ee4ded1bdf502e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save dataset\n",
    "dataset_path = \"medmcqa_tokenized.hf\"\n",
    "tokenized_dataset.save_to_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76de736-f560-4eb1-b285-2b54d3ee56bf",
   "metadata": {},
   "source": [
    "### Set Up Training Config and Updated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f9655c9-b06a-4065-80f3-e18e96597422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use saved dataframe created during dataset processing\n",
    "use_hf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77218619-17a7-4f44-a663-23ca7fb10db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": use_hf,\n",
    "        \"path\": dataset_path\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ff7976e1-f849-440a-8979-e5eca3338495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from local\n",
    "\n",
    "# TODO - loading?\n",
    "# dataset = datasets.load_dataset(dataset_path)\n",
    "\n",
    "dataset = tokenized_dataset\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "val_dataset = dataset[\"validation\"] if \"validation\" in dataset else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2bbd9fbc-276d-4387-b4bc-448b32745860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 182822\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6150\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4183\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure dataset has valid features\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1481e-1afa-4953-b371-94afe74c00dd",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d2988e79-c3a7-42cc-83ba-e85a12c63991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 1024)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de585d0-84f1-4056-8dc6-032fa945ba21",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9e22cad4-3eba-41b5-a50f-367ffa75081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens = 1000, max_output_tokens = 100):\n",
    "    # Tokenize\n",
    "    input_ids = tokenizer.encode(\n",
    "        text, \n",
    "        return_tensors = \"pt\",\n",
    "        truncation = True,\n",
    "        max_length = max_input_tokens\n",
    "    )\n",
    "    # Generate\n",
    "    device = model.device\n",
    "    generated_output_with_prompt = model.generate(\n",
    "        input_ids = input_ids.to(device),\n",
    "        max_length = max_output_tokens\n",
    "    )\n",
    "    # Decode\n",
    "    generated_text_with_prompt = tokenizer.batch_decode( # batch decode\n",
    "        generated_output_with_prompt, \n",
    "        skip_special_tokens = True\n",
    "    )\n",
    "    generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "    \n",
    "    return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "43273ff7-ad3d-41a4-a01c-06ae95fcce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): Which of the following is not true for myelinated nerve fibers:\n",
      "Correct answer: 0, None\n",
      "Model's answer: \n",
      "\n",
      "\n",
      "1.  The myelinated nerve fibers are not myelinated.\n",
      "\n",
      "2.  The myelinated nerve fibers are not myelinated.\n",
      "\n",
      "3.  The myelinated nerve fibers are not myelinated.\n",
      "\n",
      "4.  The myelinated nerve fibers are not myelinated.\n",
      "\n",
      "5.  The myelinated nerve fibers are not myelinated.\n",
      "\n",
      "6.  The myelinated nerve fibers are not\n"
     ]
    }
   ],
   "source": [
    "# base model test\n",
    "val_text = val_dataset[0]['question']\n",
    "print(\"Question input (test):\", val_text)\n",
    "print(f\"Correct answer: {val_dataset[0]['cop']}, {val_dataset[0]['exp']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference(val_text, base_model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942c236-d357-4274-8e4b-2b0e3bafca50",
   "metadata": {},
   "source": [
    "### Set Up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e63a71bf-7ead-400f-9d3e-22a0e9ac7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 5 # experiment w/ val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2c94d7b3-4c44-45fb-9f5a-7cb50bdcb15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = f\"medmcqa_{max_steps}_steps_{datetime.now()}\"\n",
    "output_dir = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "48bc980e-0c54-4b70-ac29-77a854707bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=1.0e-5,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=1,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "006cf234-f407-4d32-8f53-c2c13bc2fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 1024)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
      ")\n",
      "Memory footprint 1.72829168 GB\n",
      "Flops 17391.09433344 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_flops = (\n",
    "  base_model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, training_config[\"model\"][\"max_length\"])\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(base_model)\n",
    "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7b267c94-f17f-4c60-bbda-312b28fb37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b13ecc-1ea3-4a93-b154-aab82c3ca8d9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "324271ee-1c91-4adb-bfeb-d086944fe1be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AcceleratorState' object has no attribute 'distributed_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_output \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-experimentation/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-experimentation/lib/python3.11/site-packages/transformers/trainer.py:1569\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1567\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 1569\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_train_dataloader()\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;66;03m# Setting up training control variables:\u001b[39;00m\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;66;03m# number of training epochs: num_train_epochs\u001b[39;00m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;66;03m# number of training steps per epoch: num_update_steps_per_epoch\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;66;03m# total number of training steps to execute: max_steps\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m total_train_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mworld_size\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-experimentation/lib/python3.11/site-packages/transformers/trainer.py:829\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_drop_last\n\u001b[1;32m    827\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker_init_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m seed_worker\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mprepare(DataLoader(train_dataset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataloader_params))\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-experimentation/lib/python3.11/site-packages/accelerate/accelerator.py:1173\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(obj)\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1167\u001b[0m     ):\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1169\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded with `device_map=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` in any distributed mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mmyscript.py}}`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1171\u001b[0m         )\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   1174\u001b[0m     model_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag-experimentation/lib/python3.11/site-packages/accelerate/accelerator.py:485\u001b[0m, in \u001b[0;36mAccelerator.distributed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistributed_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdistributed_type\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AcceleratorState' object has no attribute 'distributed_type'"
     ]
    }
   ],
   "source": [
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6330d346-39b5-472b-b456-4f5c8b641d55",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7a08c34-b3c3-4ac5-824d-5aee6620aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydrating dataset with instruction prompts\n",
    "# dataset based\n",
    "\n",
    "def hydrate(dataset):\n",
    "    processed_data = []\n",
    "    \n",
    "    for row in dataset:\n",
    "        # input hydration\n",
    "        input = input_template.format(\n",
    "            question = row['question'],\n",
    "            a = row['opa'],\n",
    "            b = row['opb'],\n",
    "            c = row['opc'],\n",
    "            d = row['opd']\n",
    "        )\n",
    "        # prompt hydration\n",
    "        if row['cop'] == -1 or not row['exp']: # test dataset\n",
    "            continue\n",
    "        else: # training and val datasets\n",
    "            processed_prompt = prompt_template_with_input.format(instruction=instruction_template, input=input)\n",
    "        \n",
    "        processed_data.append({\"input\": processed_prompt, \"output\": str(row['cop']) + ': ' + row['exp']})\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "processed_data = hydrate(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
